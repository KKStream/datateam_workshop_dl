{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('./datasets/v0_eigens.npz')\n",
    "\n",
    "train_data_size = dataset['train_eigens'].shape[0]\n",
    "valid_data_size = train_data_size / 5\n",
    "train_data_size = train_data_size - valid_data_size\n",
    "\n",
    "indices = np.arange(train_data_size + valid_data_size)\n",
    "\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "train_data = dataset['train_eigens'][indices[:train_data_size]]\n",
    "valid_data = dataset['train_eigens'][indices[train_data_size:]]\n",
    "\n",
    "train_eigens = train_data[:, :-28]\n",
    "train_labels = train_data[:, -28:]\n",
    "valid_eigens = valid_data[:, :-28]\n",
    "valid_labels = valid_data[:, -28:]\n",
    "\n",
    "print 'train_eigens.shape = {}'.format(train_eigens.shape)\n",
    "print 'train_labels.shape = {}'.format(train_labels.shape)\n",
    "print 'valid_eigens.shape = {}'.format(valid_eigens.shape)\n",
    "print 'valid_labels.shape = {}'.format(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.00001\n",
    "\n",
    "w = (np.random.rand(train_eigens.shape[1], 28) * 2.0 - 1.0) * 0.01\n",
    "b = np.zeros((1, 28))\n",
    "\n",
    "valid_guesss = np.dot(valid_eigens, w) + b\n",
    "\n",
    "auc = util.auc(valid_guesss.flatten(), valid_labels.flatten())\n",
    "\n",
    "print 'auc[before]: {}'.format(auc)\n",
    "\n",
    "for step, eigens, labels in util.mini_batches(train_eigens, train_labels, batch_size, False):\n",
    "    y = np.dot(eigens, w) + b\n",
    "    \n",
    "    loss = np.sum(np.square(y - labels), axis=1)\n",
    "\n",
    "    if step % 5000 == 0:\n",
    "        print 'loss[{:>8}]: {}'.format(step, np.mean(loss))\n",
    "    \n",
    "    dl_dy = 2.0 * (y - labels)\n",
    "    dl_dw = np.mean(np.dot(eigens.T, dl_dy), axis=0)\n",
    "    dl_db = np.mean(dl_dy, axis=0)\n",
    "    \n",
    "    w = w - learning_rate * dl_dw\n",
    "    b = b - learning_rate * dl_db\n",
    "    \n",
    "    if step == 50000:\n",
    "        break\n",
    "        \n",
    "valid_guesss = np.dot(valid_eigens, w) + b\n",
    "\n",
    "auc = util.auc(valid_guesss.flatten(), valid_labels.flatten())\n",
    "\n",
    "print 'auc[after]: {}'.format(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_inception = mpimg.imread('./datasets/inception.png')\n",
    "\n",
    "plt.imshow(image_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.000008\n",
    "\n",
    "w1 = (np.random.rand(train_eigens.shape[1], 128) * 2.0 - 1.0) * 0.01\n",
    "b1 = np.zeros((1, 128))\n",
    "w2 = (np.random.rand(128, 28) * 2.0 - 1.0) * 0.01\n",
    "b2 = np.zeros((1, 28))\n",
    "\n",
    "y1 = np.dot(valid_eigens, w1) + b1\n",
    "y1[y1 < 0.0] = 0.0\n",
    "\n",
    "y2 = np.dot(y1, w2) + b2\n",
    "y2 = 1.0 / (1.0 + np.exp(-y2))\n",
    "\n",
    "valid_guesss = y2\n",
    "\n",
    "auc = util.auc(valid_guesss.flatten(), valid_labels.flatten())\n",
    "\n",
    "print 'auc[before]: {}'.format(auc)\n",
    "\n",
    "for step, eigens, labels in util.mini_batches(train_eigens, train_labels, batch_size, False):\n",
    "    y1 = np.dot(eigens, w1) + b1\n",
    "    y1[y1 < 0.0] = 0.0\n",
    "\n",
    "    y2 = np.dot(y1, w2) + b2\n",
    "   \n",
    "    loss = np.sum(np.square(y2 - labels), axis=1)\n",
    "\n",
    "    if step % 5000 == 0:\n",
    "        print 'loss[{:>8}]: {}'.format(step, np.mean(loss))\n",
    "    \n",
    "    dl_dy2 = 2.0 * (y2 - labels)\n",
    "    dl_dw2 = np.mean(np.dot(y1.T, dl_dy2), axis=0)\n",
    "    dl_db2 = np.mean(dl_dy2, axis=0)\n",
    "\n",
    "    dl_dy1 = np.dot(dl_dy2, w2.T)\n",
    "    dl_dw1 = np.mean(np.dot(eigens.T, dl_dy1), axis=0)\n",
    "    dl_db1 = np.mean(dl_dy1, axis=0)\n",
    "    \n",
    "    w2 = w2 - learning_rate * dl_dw2\n",
    "    b2 = b2 - learning_rate * dl_db2\n",
    "    \n",
    "    w1 = w1 - learning_rate * dl_dw1\n",
    "    b1 = b1 - learning_rate * dl_db1\n",
    "    \n",
    "    if step == 50000:\n",
    "        break\n",
    "        \n",
    "y1 = np.dot(valid_eigens, w1) + b1\n",
    "y1[y1 < 0.0] = 0.0\n",
    "\n",
    "y2 = np.dot(y1, w2) + b2\n",
    "y2 = 1.0 / (1.0 + np.exp(-y2))\n",
    "\n",
    "valid_guesss = y2\n",
    "\n",
    "auc = util.auc(valid_guesss.flatten(), valid_labels.flatten())\n",
    "\n",
    "print 'auc[after]: {}'.format(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
